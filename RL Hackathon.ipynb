{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.26.2 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.26.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym==0.26.2) (1.23.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym==0.26.2) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym==0.26.2) (0.0.8)\n"
     ]
    }
   ],
   "source": [
    "pip install gym==0.26.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[toy_text] in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[toy_text]) (1.23.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[toy_text]) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[toy_text]) (0.0.8)\n",
      "Requirement already satisfied: pygame==2.1.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[toy_text]) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gym 0.26.2 does not provide the extra 'toy-text'\n"
     ]
    }
   ],
   "source": [
    "pip install gym[toy_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'FrozenLake-v1'\n",
    "env = gym.make(environment_name, render_mode= 'ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'S', 'S', 'S', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'F', 'F', 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'F', 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'F', 'S', 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'F', 'F', 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'F', 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'S', 'F', 'F', 'F', 'F', 'S', 'S', 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "Path taken during the episode with reward 1: [(0, {'prob': 1}), 'S', 'S', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "The score for 999 episodes is :14.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 1000\n",
    "score = 0\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    path_taken = []  # List to store states for the current episode\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        path_taken.append(state)  # Record the current state\n",
    "\n",
    "        score += reward\n",
    "\n",
    "        state = next_state\n",
    "    if reward == 1.0:\n",
    "        # Convert byte strings to regular strings and extract state information from tuples\n",
    "        readable_path = [\n",
    "            state[1].decode('utf-8') if isinstance(state, tuple) and isinstance(state[1], bytes) else\n",
    "            env.desc[state // env.ncol, state % env.ncol].decode('utf-8') if isinstance(state, int) else\n",
    "            state for state in path_taken\n",
    "        ]\n",
    "        print(\"Path taken during the episode with reward 1:\", readable_path)\n",
    "\n",
    "print(f\"The score for {episodes} episodes is :{score}\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym==0.7.4\n",
      "  Using cached gym-0.7.4-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym==0.7.4) (1.23.1)\n",
      "Requirement already satisfied: requests>=2.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym==0.7.4) (2.28.1)\n",
      "Requirement already satisfied: six in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym==0.7.4) (1.16.0)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym==0.7.4) (2.0.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0->gym==0.7.4) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0->gym==0.7.4) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0->gym==0.7.4) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0->gym==0.7.4) (2022.9.14)\n",
      "Installing collected packages: gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "Successfully installed gym-0.7.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym==0.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-08 23:37:40,695] Making new env: FrozenLake-v0\n",
      "c:\\Users\\abhay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\envs\\registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "environment_name = 'FrozenLake-v0'\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_states = env.observation_space.n\n",
    "number_of_actions = env.action_space.n\n",
    "\n",
    "steps_total = []\n",
    "rewards_total = []\n",
    "egreedy_total = []\n",
    "\n",
    "gamma = 0.95\n",
    "learning_rate = 0.9\n",
    "\n",
    "egreedy = 0.7\n",
    "egreedy_final = 0.1\n",
    "egreedy_decay = 0.999\n",
    "\n",
    "Q = torch.zeros([number_of_states, number_of_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q table \n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6 Reward: 1.0 Steps Taken: 10\n",
      "Episode: 131 Reward: 1.0 Steps Taken: 10\n",
      "Episode: 185 Reward: 1.0 Steps Taken: 12\n",
      "Episode: 197 Reward: 1.0 Steps Taken: 8\n",
      "Episode: 228 Reward: 1.0 Steps Taken: 12\n",
      "Episode: 239 Reward: 1.0 Steps Taken: 6\n",
      "Episode: 261 Reward: 1.0 Steps Taken: 14\n",
      "Episode: 266 Reward: 1.0 Steps Taken: 9\n",
      "Episode: 271 Reward: 1.0 Steps Taken: 9\n",
      "Episode: 301 Reward: 1.0 Steps Taken: 27\n",
      "Episode: 413 Reward: 1.0 Steps Taken: 17\n",
      "Episode: 420 Reward: 1.0 Steps Taken: 21\n",
      "Episode: 434 Reward: 1.0 Steps Taken: 15\n",
      "Episode: 435 Reward: 1.0 Steps Taken: 19\n",
      "Episode: 476 Reward: 1.0 Steps Taken: 24\n",
      "Episode: 480 Reward: 1.0 Steps Taken: 17\n",
      "Episode: 488 Reward: 1.0 Steps Taken: 30\n",
      "Episode: 490 Reward: 1.0 Steps Taken: 25\n",
      "Episode: 491 Reward: 1.0 Steps Taken: 10\n",
      "Episode: 493 Reward: 1.0 Steps Taken: 35\n",
      "Episode: 499 Reward: 1.0 Steps Taken: 18\n",
      "Episode: 546 Reward: 1.0 Steps Taken: 19\n",
      "Episode: 598 Reward: 1.0 Steps Taken: 11\n",
      "Episode: 628 Reward: 1.0 Steps Taken: 13\n",
      "Episode: 722 Reward: 1.0 Steps Taken: 12\n",
      "Episode: 723 Reward: 1.0 Steps Taken: 21\n",
      "Episode: 724 Reward: 1.0 Steps Taken: 11\n",
      "Episode: 750 Reward: 1.0 Steps Taken: 21\n",
      "Episode: 795 Reward: 1.0 Steps Taken: 18\n",
      "Episode: 868 Reward: 1.0 Steps Taken: 10\n",
      "Episode: 883 Reward: 1.0 Steps Taken: 21\n",
      "Episode: 910 Reward: 1.0 Steps Taken: 57\n",
      "Episode: 917 Reward: 1.0 Steps Taken: 26\n",
      "Episode: 988 Reward: 1.0 Steps Taken: 12\n",
      "The score for 1000 episodes is :34.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 1000\n",
    "score = 0\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    \n",
    "    # resets the environment\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        random_for_egreedy = torch.rand(1)[0]\n",
    "        \n",
    "\n",
    "        if random_for_egreedy > egreedy:      \n",
    "            random_values = Q[state] + torch.rand(1,number_of_actions) / 1000      \n",
    "            action = torch.max(random_values,1)[1][0]  \n",
    "            action = action.item()\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        if egreedy > egreedy_final:\n",
    "            egreedy *= egreedy_decay\n",
    "        \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Filling the Q Table\n",
    "        Q[state, action] = reward + gamma * torch.max(Q[new_state])\n",
    "\n",
    "        score += reward\n",
    "        \n",
    "        # Setting new state for next action\n",
    "        state = new_state\n",
    "        \n",
    "        # env.render()\n",
    "        # time.sleep(0.4)\n",
    "        \n",
    "        if done:\n",
    "            steps_total.append(step)\n",
    "            rewards_total.append(reward)\n",
    "            egreedy_total.append(egreedy)\n",
    "            if reward == 1.0:\n",
    "                print('Episode: {} Reward: {} Steps Taken: {}'.format(i_episode,reward, step))\n",
    "            break\n",
    "\n",
    "print(f\"The score for {episodes} episodes is :{score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1105e-04, 2.8711e-04, 2.8711e-04, 2.8711e-04],\n",
       "        [0.0000e+00, 2.7276e-04, 3.3487e-04, 2.5912e-04],\n",
       "        [0.0000e+00, 3.5250e-04, 0.0000e+00, 3.3487e-04],\n",
       "        [3.7105e-04, 0.0000e+00, 0.0000e+00, 3.3487e-04],\n",
       "        [2.2216e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 9.5000e-01, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updated Q table \n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
